//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33492891
// Cuda compilation tools, release 12.3, V12.3.103
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	_Z14kernel_if_elsePi

.visible .entry _Z14kernel_if_elsePi(
	.param .u64 _Z14kernel_if_elsePi_param_0
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z14kernel_if_elsePi_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 1;
	setp.eq.b32 	%p1, %r2, 1;
	mul.lo.s32 	%r3, %r1, 3;
	shl.b32 	%r4, %r1, 1;
	selp.b32 	%r5, %r3, %r4, %p1;
	mul.wide.s32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.u32 	[%rd4], %r5;
	ret;

}
	// .globl	_Z20kernel_nested_branchPi
.visible .entry _Z20kernel_nested_branchPi(
	.param .u64 _Z20kernel_nested_branchPi_param_0
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd2, [_Z20kernel_nested_branchPi_param_0];
	cvta.to.global.u64 	%rd3, %rd2;
	mov.u32 	%r1, %tid.x;
	setp.lt.s32 	%p1, %r1, 16;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd1, %rd3, %rd4;
	@%p1 bra 	$L__BB1_2;
	bra.uni 	$L__BB1_1;

$L__BB1_2:
	and.b32  	%r3, %r1, 3;
	setp.eq.s32 	%p2, %r3, 0;
	@%p2 bra 	$L__BB1_4;

	mov.u32 	%r4, 20;
	st.global.u32 	[%rd1], %r4;
	bra.uni 	$L__BB1_5;

$L__BB1_1:
	mov.u32 	%r2, 30;
	st.global.u32 	[%rd1], %r2;
	bra.uni 	$L__BB1_5;

$L__BB1_4:
	mov.u32 	%r5, 10;
	st.global.u32 	[%rd1], %r5;

$L__BB1_5:
	ret;

}
	// .globl	_Z18kernel_shared_flagPi
.visible .entry _Z18kernel_shared_flagPi(
	.param .u64 _Z18kernel_shared_flagPi_param_0
)
{
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z18kernel_shared_flagPi_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	bar.sync 	0;
	add.s32 	%r2, %r1, 100;
	mul.wide.s32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.u32 	[%rd4], %r2;
	ret;

}

